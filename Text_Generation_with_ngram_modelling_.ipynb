{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Text Generation with ngram modelling (1).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chitreshkr/AI-Workshop/blob/master/Text_Generation_with_ngram_modelling_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8dcMWoCIDol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7mrIBB5IDoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = list(pd.read_csv('yelp.csv')['text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzOTjpb7IDos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, s in enumerate(sentences):\n",
        "    sentences[i] = s.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUvS9TmzIDou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import reuters\n",
        "from nltk import bigrams, trigrams\n",
        "from collections import Counter, defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3CHT2oqIDow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a placeholder for model\n",
        "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "\n",
        "# Count frequency of co-occurance  \n",
        "for sentence in sentences:\n",
        "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
        "        model[(w1, w2)][w3] += 1\n",
        " \n",
        "# Let's transform the counts to probabilities\n",
        "for w1_w2 in model:\n",
        "    total_count = float(sum(model[w1_w2].values()))\n",
        "    for w3 in model[w1_w2]:\n",
        "        model[w1_w2][w3] /= total_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "M7P_ItwDIDoy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "6921e0c3-87d7-45db-be9c-f4c4541882ca"
      },
      "source": [
        "dict(model[\"beer\", \"is\"])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'$2.00': 0.03571428571428571,\n",
              " 'a': 0.03571428571428571,\n",
              " 'also': 0.07142857142857142,\n",
              " 'astounding': 0.03571428571428571,\n",
              " 'awesome.': 0.03571428571428571,\n",
              " 'cold.': 0.03571428571428571,\n",
              " 'even': 0.03571428571428571,\n",
              " 'excellent,': 0.03571428571428571,\n",
              " 'fantastic,': 0.03571428571428571,\n",
              " 'fine': 0.03571428571428571,\n",
              " 'fresh': 0.03571428571428571,\n",
              " 'great': 0.03571428571428571,\n",
              " 'great,': 0.07142857142857142,\n",
              " 'just': 0.03571428571428571,\n",
              " 'legendary': 0.03571428571428571,\n",
              " 'like...the': 0.03571428571428571,\n",
              " 'on': 0.03571428571428571,\n",
              " 'poured,': 0.03571428571428571,\n",
              " 'pretty': 0.03571428571428571,\n",
              " 'really': 0.07142857142857142,\n",
              " 'so': 0.03571428571428571,\n",
              " 'super': 0.03571428571428571,\n",
              " 'tiny': 0.03571428571428571,\n",
              " 'why': 0.03571428571428571,\n",
              " 'your': 0.03571428571428571}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUx820cUIDo1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "180791a7-5414-4ad0-b9e3-b719705314ae"
      },
      "source": [
        "import random\n",
        "\n",
        "# starting words\n",
        "text = [\"the\", \"food\"]\n",
        "sentence_finished = False\n",
        " \n",
        "while not sentence_finished:\n",
        "    # select a random probability threshold  \n",
        "    r = random.random()\n",
        "    accumulator = .0\n",
        "\n",
        "    for word in model[tuple(text[-2:])].keys():\n",
        "        accumulator += model[tuple(text[-2:])][word]\n",
        "        # select words that are above the probability threshold\n",
        "        if accumulator >= r:\n",
        "            text.append(word)\n",
        "            break\n",
        "\n",
        "    if text[-2:] == [None, None]:\n",
        "        sentence_finished = True\n",
        "\n",
        "print (' '.join([t for t in text if t]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the food is as good as last night. We did not even nice!) and not homemade :( sad to see what their getting into their kitchen from the past, the potato chips on there other sushis are actually there helping them out myself for not burning the bean dip, and hot sauce for the minute your dogs are my pros and cons on a Monday night. We went here for a glass window. We were sitting on the sides that were cold :(. I guess I'll have to get it local? It has tomato, lettuce, red onion, and delicious candied pecans....with a balsamic reduction drizzle, with a retro feel (Urban Outfitters, maybe?), dark wood, the high star reviews come from here. If you are into choices, then Gelato 64 has got to spend a decent Italian Beef sandwiches to. The orange martini they have a few minutes, the Chimichanga Entr√©e caught my eye on your smart phone and started to fuss on and on). I really don't watch their children there eating and don't know what's up with a urban funk to it. Before we could stand. Normally I ask for crispy won tons to add 1, instead of Teese. Daiya tastes much better, in my room quite quick and the food bar, nor outside... Indeed, it seemed as though the upstairs is better than mine did. All thanks to them. Just wish that this place is a great place - enjoy my meal. And the food was outstanding, although the drinks were good. The crunch roll was barely able to speak to them). At least they always take the Orbit to downtown Phoenix soon. To which I dipped in a quite plaza In Chandler AZ, is an amazing dinner tonight and will go back for more!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp51gitsIDo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}